{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c00ee67-d7e5-45ab-a6da-9cc8a185fedc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Masked Observations with NumPyro\n",
    "We are interested in building a factorized model in NumPyro that is a highly simplified version of retail shopping, where a customer with features $X$ decides whether or not to visit a store and which items in the store to purchase if they do visit. NumPyro provides an effect handler `mask` that seems like it could handle the job. This notebook explores if this effect handler indeed helps us to correctly estimate the model parameters.\n",
    "\n",
    "\n",
    "## Model description\n",
    "Let $X \\in \\mathbb{R}^D$  be a vector of features of length $D$.\n",
    "\n",
    "We aim to model the joint probability $P(Y_0, Y_1 | X)$ where:\n",
    "\n",
    " - $Y_0$ is a binary outcome.\n",
    " - $Y_1 \\in \\{0, 1\\}^I$ is a vector of binary outcomes of length $I$.\n",
    " \n",
    " \n",
    "The model assumes that $Y_0 = 0$ implies all values in $Y_1$ are unobserved. This allows us to decompose the joint probability as\n",
    "$$\n",
    "P(Y_0, Y_1 \\mid X)= P(Y_0 \\mid X) \\times P(Y_1 \\mid Y_0 = 1, X)\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "### Modeling $P(Y_0 | X)$\n",
    "\n",
    "We use a logistic regression model to model $P(Y_0 \\mid X)$:\n",
    "$$\n",
    "\\text{logit}(P(Y_0 = 1 \\mid X)) = X^\\top \\beta_{Y_0} + \\alpha_{Y_0}\n",
    "$$\n",
    "\n",
    "Thus,\n",
    "$$\n",
    "P(Y_0 = 1 | X) = \\frac{1}{1 + \\exp(-(X^\\top \\beta_{Y_0} + \\alpha_{Y_0}))},\n",
    "$$\n",
    "and\n",
    "$$\n",
    "P(Y_0 = 0 | X) = 1 - P(Y_0 = 1 | X).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d242e9b-e0d6-42bb-9b8c-f75000f191ec",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Modeling $P(Y_1 | Y_0 = 1, X))$\n",
    "\n",
    "Conditioned on $Y_0 = 1$, we model $Y_1$ as independent binary outcomes using logistic regression:\n",
    "$$\n",
    "\\text{logit}(P(Y_{1,i} = 1 | Y_0 = 1, X)) = X^\\top \\beta_{Y_{1,i}} + \\alpha_{Y_{1,i}}, \\quad \\forall i \\in \\{1, \\ldots, n_{\\text{I}}\\},\n",
    "$$\n",
    "\n",
    "Thus,\n",
    "$$\n",
    "P(Y_{1,i} = 1 | Y_0 = 1, X) = \\frac{1}{1 + \\exp(-X^\\top \\beta_{Y_{1,i}} - \\alpha_{Y_{1,i}})},\n",
    "$$\n",
    "and\n",
    "$$\n",
    "P(Y_{1,i} = 0 | Y_0 = 1, X) = 1 - P(Y_{1,i} = 1 | Y_0 = 1, X).\n",
    "$$\n",
    "\n",
    "Combining these, the joint probability becomes:\n",
    "$$\n",
    "P(Y_0, Y_1 | X) =\n",
    "\\begin{cases} \n",
    "P(Y_0 = 0 | X) & \\text{if } Y_0 = 0, Y_1 = 0, \\\\\n",
    "P(Y_0 = 1 | X) \\times \\prod_{i=1}^{n_{\\text{products}}} P(Y_{1,i} | Y_0 = 1, X) & \\text{if } Y_0 = 1.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "# Simulated dataset\n",
    "We simulate some data according to this model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4e16418a-3d67-4e82-a2d4-30b43e58c6e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.infer import MCMC, NUTS, Predictive\n",
    "from numpyro.handlers import mask\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "# Generate some synthetic data\n",
    "np.random.seed(0)\n",
    "N = 10000 # number of observations\n",
    "D = 3 # number of features\n",
    "I = 2# number of items\n",
    "\n",
    "X = np.random.randn(N, D)\n",
    "\n",
    "# Generate synthetic true parameters\n",
    "true_beta_Y0 = np.random.randn(1, D)\n",
    "true_intercept_Y0 = 10*np.random.randn(1)\n",
    "logits_Y0 = np.dot(X, true_beta_Y0.T).flatten() + true_intercept_Y0\n",
    "probabilities_Y0 = 1 / (1 + np.exp(-logits_Y0))\n",
    "y0 = np.random.binomial(1, probabilities_Y0)\n",
    "\n",
    "true_beta_Y1_given_Y0 = np.random.randn(I, D)\n",
    "true_intercept_Y1_given_Y0 = np.random.randn(I)\n",
    "X_Y0 = X[y0 == 1]\n",
    "\n",
    "logits_Y1_given_Y0 = np.dot(X_Y0, true_beta_Y1_given_Y0.T) + true_intercept_Y1_given_Y0\n",
    "probabilities_Y1_given_Y0 = 1 / (1 + np.exp(-logits_Y1_given_Y0))\n",
    "y1 = np.zeros((N, I), dtype=int)\n",
    "y1[y0 == 1] = np.random.binomial(1, probabilities_Y1_given_Y0)\n",
    "\n",
    "# Convert data to JAX arrays\n",
    "X = jnp.array(X)\n",
    "y0 = jnp.array(y0)\n",
    "y1 = jnp.array(y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e189e7e-9fac-45c6-a1df-e97566c6cf7a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# NumPyro Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1f34b90c-45d1-4eb3-ae67-a515303d7975",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def logit_choice_model(X, name_prefix, n_outputs):\n",
    "    n_features = X.shape[1]\n",
    "    beta = numpyro.sample(f'{name_prefix}_beta', dist.Normal(jnp.zeros((n_outputs, n_features)), jnp.ones((n_outputs, n_features))))\n",
    "    intercept = numpyro.sample(f'{name_prefix}_intercept', dist.Normal(jnp.zeros(n_outputs), 1.))\n",
    "    linear_combination = jnp.einsum('ij,kj->ik', X, beta) + intercept\n",
    "    return jax.nn.sigmoid(linear_combination)\n",
    "\n",
    "def simple_model(X, I, y0=None, y1=None):\n",
    "    \"\"\" This model neglects to mask any observations where Y_0=0 but it's a good baseline to get the code working.\n",
    "    Parameter estimates are expected to be biased.\n",
    "    \"\"\"\n",
    "    # Model P(Y0 | X)\n",
    "    P_Y0 = logit_choice_model(X, 'Y0', 1).squeeze()\n",
    "\n",
    "    # Sample Y0\n",
    "    y0_sample = numpyro.sample('y0', dist.Bernoulli(P_Y0), obs=y0)  \n",
    "\n",
    "    # Model P(Y1 | Y0 = 1, X)\n",
    "    P_Y1_given_Y0 = logit_choice_model(X, 'Y1_given_Y0', I)  \n",
    "\n",
    "    with numpyro.plate('products', I, dim=-1):\n",
    "        with numpyro.plate('data_y1', X.shape[0]):\n",
    "               numpyro.sample('y1', dist.Bernoulli(P_Y1_given_Y0), obs=y1)\n",
    "\n",
    "                \n",
    "\n",
    "def mask_handler_model(X, I, y0=None, y1=None):\n",
    "    \"\"\"This model uses the mask effect handler to mask observations where y_0=0 to estimate the correct model parameters .  \n",
    "    \"\"\"\n",
    "    # Model P(Y0 | X)\n",
    "    P_Y0 = logit_choice_model(X, 'Y0', 1).squeeze()\n",
    "\n",
    "    # Sample Y0\n",
    "    y0_sample = numpyro.sample('y0', dist.Bernoulli(P_Y0), obs=y0)  \n",
    "\n",
    "    # Masking to filter out Y1 calculations when Y0 is 0\n",
    "    mask_array = (y0_sample == 1)[:, None]\n",
    "\n",
    "    # Model P(Y1 | Y0 = 1, X)\n",
    "    P_Y1_given_Y0 = logit_choice_model(X, 'Y1_given_Y0', I)  \n",
    "\n",
    "    with numpyro.plate('products', I, dim=-1):\n",
    "        with numpyro.plate('data_y1', X.shape[0]):\n",
    "            with mask(mask=mask_array):\n",
    "               numpyro.sample('y1', dist.Bernoulli(P_Y1_given_Y0), obs=y1)\n",
    "\n",
    "\n",
    "\n",
    "def get_predictive_posterior_samples(model):          \n",
    "    # Define the NUTS sampler\n",
    "    nuts_kernel = NUTS(model)\n",
    "\n",
    "    # Run MCMC to sample from the posterior\n",
    "    mcmc = MCMC(nuts_kernel, num_warmup=500, num_samples=1000)\n",
    "    mcmc.run(jax.random.PRNGKey(0), X, I, y0, y1)\n",
    "    return mcmc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48abdb7-51eb-4d46-8291-c70dd3c88798",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Parameter Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "91216bfb-4148-4830-a414-a6c26b276cb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:08<00:00, 178.81it/s, 7 steps of size 6.25e-01. acc. prob=0.89]\n",
      "sample: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:08<00:00, 171.85it/s, 7 steps of size 5.28e-01. acc. prob=0.91]\n"
     ]
    }
   ],
   "source": [
    "simple_param_estimates = get_predictive_posterior_samples(simple_model)\n",
    "mask_handler_param_estimates = get_predictive_posterior_samples(mask_handler_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "aedf90d4-b2f7-40e0-a71c-95270daba61b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "param_names = [\"Y0_beta\", \"Y0_intercept\", \"Y1_given_Y0_beta\", \"Y1_given_Y0_intercept\"]\n",
    "\n",
    "ground_truth = {\n",
    " \"Y0_beta\": true_beta_Y0,\n",
    " \"Y0_intercept\": true_intercept_Y0, \n",
    " \"Y1_given_Y0_beta\": true_beta_Y1_given_Y0, \n",
    " \"Y1_given_Y0_intercept\": true_intercept_Y1_given_Y0 \n",
    "}\n",
    "    \n",
    "\n",
    "sites = simple_param_estimates._states[simple_param_estimates._sample_field]\n",
    "simple_param_summary_stats = numpyro.diagnostics.summary(sites)\n",
    "\n",
    "sites = mask_handler_param_estimates._states[mask_handler_param_estimates._sample_field]\n",
    "mask_handler_param_summary_stats = numpyro.diagnostics.summary(sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "bb93bd49-e247-4d4a-9b21-13ac01d25398",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y0_beta\n",
      "   ground_truth      mean       std\n",
      "0      0.371232  0.355485  0.024675\n",
      "1      0.304784  0.290453  0.025540\n",
      "2      0.504125  0.475702  0.027870\n",
      "\n",
      "Y0_intercept\n",
      "   ground_truth      mean       std\n",
      "0      1.352996  1.345138  0.026762\n",
      "\n",
      "Y1_given_Y0_beta\n",
      "   ground_truth      mean       std\n",
      "0     -2.474242 -1.030060  0.029048\n",
      "1     -1.462732 -0.525774  0.025773\n",
      "2      1.257190  0.879122  0.026619\n",
      "3      2.196709  1.466483  0.032559\n",
      "4     -0.646848 -0.204878  0.025808\n",
      "5      0.477828  0.511528  0.025175\n",
      "\n",
      "Y1_given_Y0_intercept\n",
      "   ground_truth      mean       std\n",
      "0      0.448704 -0.461200  0.024793\n",
      "1      0.887091  0.016012  0.023572\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for param_name in param_names:\n",
    "    print(param_name)\n",
    "    param_stats = pd.DataFrame({key: value.flatten() for key, value in simple_param_summary_stats[param_name].items()})\n",
    "    param_stats.insert(0, 'ground_truth',ground_truth[param_name].flatten())\n",
    "    print(param_stats.iloc[:,:3])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2765d30-93f4-4fc8-8e90-7e0eaeb95d0b",
   "metadata": {
    "tags": []
   },
   "source": [
    "From inspection, we can see the parameter estimates for our simple model are not correct. Now let's look at the model with masking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d0c61a7e-e5ed-443a-affd-428f85c52eb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y0_beta\n",
      "   ground_truth      mean       std\n",
      "0      0.371232  0.354625  0.025204\n",
      "1      0.304784  0.289758  0.025788\n",
      "2      0.504125  0.475834  0.025870\n",
      "\n",
      "Y0_intercept\n",
      "   ground_truth      mean       std\n",
      "0      1.352996  1.345155  0.025662\n",
      "\n",
      "Y1_given_Y0_beta\n",
      "   ground_truth      mean       std\n",
      "0     -2.474242 -2.559169  0.060795\n",
      "1     -1.462732 -1.450007  0.046866\n",
      "2      1.257190  1.282532  0.043331\n",
      "3      2.196709  2.290085  0.053606\n",
      "4     -0.646848 -0.649854  0.037008\n",
      "5      0.477828  0.455630  0.035820\n",
      "\n",
      "Y1_given_Y0_intercept\n",
      "   ground_truth      mean       std\n",
      "0      0.448704  0.516614  0.038727\n",
      "1      0.887091  0.953112  0.034819\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for param_name in param_names:\n",
    "    print(param_name)\n",
    "    param_stats = pd.DataFrame({key: value.flatten() for key, value in mask_handler_param_summary_stats[param_name].items()})\n",
    "    param_stats.insert(0, 'ground_truth',ground_truth[param_name].flatten())\n",
    "    print(param_stats.iloc[:,:3])\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
